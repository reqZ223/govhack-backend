{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8416a2-9193-4ead-bde2-c1880c9197d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain tavily-python langgraph matplotlib langchain_community langchain-openai scikit-learn langchainhub langchain-ollama nomic[local]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d9685c-2af7-4eb7-9742-d86960be108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"govhack-rag-model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5814aec7-3140-4cc7-9919-eb4d4ff287f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munys\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_core.tools import tool\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/academics-and-professionals\",\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/australian-defence-force\",\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/awards-and-honours\",\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/diplomats\",\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/judiciary\",\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/parliaments-and-councils\",\n",
    "    \"https://www.stylemanual.gov.au/grammar-punctuation-and-conventions/titles-honours-forms-address/royalty-vice-royalty-and-nobility\"\n",
    "]\n",
    "\n",
    "\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add the document chunks to the \"vector store\" using NomicEmbeddings\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac6bd83a-5e80-4ed5-b70d-b3a35478c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8df3ed2-089d-4a40-abd6-dd355588e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "    Your functions are to paraphrase based on the Australian Government Style Manual. \n",
    "\n",
    "    You must also cite the relevant sources that you used to paraphrase. \n",
    "    \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    \n",
    "    Question: {question} \n",
    "    Documents: {documents} \n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f46cccd5-ee72-479a-9d50-fa6185f5fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example question\n",
    "question = '''\n",
    "A super pension is a series of regular payments made as a super income stream. This doesn't include government payments such as the age pension.\n",
    "\n",
    "You may receive these payments:\n",
    "\n",
    "from an Australian super fund, life assurance company or retirement savings account (RSA) provider\n",
    "from a fund established for the benefit of Commonwealth, state or territory employees and their dependants, such as\n",
    "the Commonwealth Superannuation Scheme\n",
    "the Public Sector Superannuation Scheme\n",
    "as a result of another person's death (death benefit income stream).\n",
    "Depending on your age and the type of income stream you receive, you may need to declare different items in your tax return. This includes:\n",
    "\n",
    "a taxed element – the part of your benefit on which tax has already been paid in the fund\n",
    "an untaxed element – the part of your benefit that is still taxable because tax has not been paid in the fund\n",
    "a tax-free component – the part of your benefit that is tax-free.\n",
    "Your PAYG payment summary – superannuation income stream from your super fund will show the amount you need to declare in your tax return. We pre-fill the amounts from your payment summary when you prepare and lodge you tax return online.\n",
    "'''\n",
    "\n",
    "# Retrieve relevant documents from the vector store based on the question\n",
    "retrieved_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "# Concatenate the retrieved documents' content\n",
    "documents = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Define the input for the chain\n",
    "input_values = {\n",
    "    \"question\": question,\n",
    "    \"documents\": documents\n",
    "}\n",
    "\n",
    "# Generate the output by running the chain with the input values\n",
    "output = rag_chain.invoke(input_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3340bbfd-af8e-43ff-9464-8344b8f4d9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
